{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shino\\mustgit\\auto_encoder.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shino/mustgit/auto_encoder.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shino/mustgit/auto_encoder.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shino/mustgit/auto_encoder.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shino/mustgit/auto_encoder.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(folder_path, img_size=(100, 100), num_images=None, random_seed=None):\n",
    "    images = []\n",
    "    image_files = [filename for filename in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, filename)) and\n",
    "                   filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "    if num_images is not None:\n",
    "        if random_seed is not None:\n",
    "            np.random.seed(random_seed)\n",
    "        selected_files = np.random.choice(image_files, num_images, replace=False)\n",
    "    else:\n",
    "        selected_files = image_files\n",
    "\n",
    "    for filename in selected_files:\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, img_size)\n",
    "                images.append(img.flatten())\n",
    "            else:\n",
    "                print(f\"Error loading {img_path}. Skipping this image.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {str(e)}. Skipping this image.\")\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "def apply_pca(images, n_components=50):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(images)\n",
    "    reconstructed_images = pca.inverse_transform(pca_result)\n",
    "    return pca_result, reconstructed_images, pca.components_\n",
    "\n",
    "def display_images(original_images, reconstructed_images, img_size=(100, 100), num_images=5):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(original_images[i].reshape(img_size), cmap='gray')\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(2, num_images, i + 1 + num_images)\n",
    "        plt.imshow(reconstructed_images[i].reshape(img_size), cmap='gray')\n",
    "        plt.title('Reconstructed (PCA)')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_pca_components(components, img_size=(100, 100), num_components=3):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    for i in range(num_components):\n",
    "        plt.subplot(1, num_components, i + 1)\n",
    "        plt.imshow(components[i].reshape(img_size), cmap='gray')\n",
    "        plt.title(f'Principal Component {i+1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_images2(original_images, reconstructed_images1, reconstructed_images2, img_size=(100, 100), num_images=5):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i in range(num_images):\n",
    "        # Display original images\n",
    "        plt.subplot(3, num_images, i + 1)\n",
    "        plt.imshow(original_images[i].reshape(img_size), cmap='gray')\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Display Autoencoder reconstructed images\n",
    "        plt.subplot(3, num_images, i + 1 + num_images)\n",
    "        plt.imshow(reconstructed_images1[i].reshape(img_size), cmap='gray')\n",
    "        plt.title('Re AE')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Display VAE reconstructed images\n",
    "        plt.subplot(3, num_images, i + 1 + 2 * num_images)\n",
    "        plt.imshow(reconstructed_images2[i].reshape(img_size), cmap='gray')\n",
    "        plt.title('Re VAE')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def build_autoencoder(input_size, encoding_dim):\n",
    "    input_img = Input(shape=(input_size,))\n",
    "\n",
    "    encoded = Dense(256, activation='relu')(input_img)\n",
    "    encoded = Dense(128, activation='relu')(encoded)\n",
    "    encoded = Dense(64, activation='relu')(encoded)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "    encoded = Dense(16, activation='relu')(encoded)\n",
    "    encoded = Dense(8, activation='relu')(encoded)\n",
    "    encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "    decoded = Dense(8, activation='relu')(encoded)\n",
    "    decoded = Dense(16, activation='relu')(decoded)\n",
    "    decoded = Dense(32, activation='relu')(decoded)\n",
    "    decoded = Dense(64, activation='relu')(decoded)\n",
    "    decoded = Dense(128, activation='relu')(decoded)\n",
    "    decoded = Dense(256, activation='relu')(decoded)\n",
    "    decoded = Dense(input_size, activation='sigmoid')(decoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "def train_autoencoder(images, encoding_dim=10, epochs=50, batch_size=32):\n",
    "    input_size = images.shape[1]\n",
    "    autoencoder = build_autoencoder(input_size, encoding_dim)\n",
    "    scaler = MinMaxScaler()\n",
    "    images_scaled = scaler.fit_transform(images)\n",
    "    x_train, x_test = train_test_split(images_scaled, test_size=0.2, random_state=42)\n",
    "    autoencoder.fit(x_train, x_train, epochs=epochs, batch_size=batch_size, shuffle=True, validation_data=(x_test, x_test))\n",
    "    return autoencoder\n",
    "\n",
    "def apply_autoencoder(autoencoder, images):\n",
    "    scaler = MinMaxScaler()\n",
    "    images_scaled = scaler.fit_transform(images)\n",
    "    reconstructed_images = autoencoder.predict(images_scaled)\n",
    "    reconstructed_images = scaler.inverse_transform(reconstructed_images)\n",
    "    return reconstructed_images\n",
    "\n",
    "\n",
    "def build_vae(input_size, encoding_dim):\n",
    "    input_img = Input(shape=(input_size,))\n",
    "    h = Dense(256, activation='relu')(input_img)\n",
    "    z_mean = Dense(encoding_dim)(h)\n",
    "    z_log_var = Dense(encoding_dim)(h)\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    z = Lambda(sampling, output_shape=(encoding_dim,))([z_mean, z_log_var])\n",
    "\n",
    "    decoder_h = Dense(256, activation='relu')\n",
    "    decoder_mean = Dense(input_size, activation='sigmoid')\n",
    "    h_decoded = decoder_h(z)\n",
    "    x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "    vae = Model(input_img, x_decoded_mean)\n",
    "\n",
    "    xent_loss = input_size * K.mean(K.binary_crossentropy(input_img, x_decoded_mean))\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = xent_loss + kl_loss\n",
    "\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer=Adam(learning_rate=0.001))\n",
    "    return vae\n",
    "\n",
    "def train_vae(images, encoding_dim=10, epochs=50, batch_size=32):\n",
    "    input_size = images.shape[1]\n",
    "    vae = build_vae(input_size, encoding_dim)\n",
    "    scaler = MinMaxScaler()\n",
    "    images_scaled = scaler.fit_transform(images)\n",
    "    x_train, x_test = train_test_split(images_scaled, test_size=0.2, random_state=42)\n",
    "    vae.fit(x_train, epochs=epochs, batch_size=batch_size, shuffle=True, validation_data=(x_test, None))\n",
    "    return vae\n",
    "\n",
    "def apply_vae(vae, images):\n",
    "    scaler = MinMaxScaler()\n",
    "    images_scaled = scaler.fit_transform(images)\n",
    "    reconstructed_images = vae.predict(images_scaled)\n",
    "    reconstructed_images = scaler.inverse_transform(reconstructed_images)\n",
    "    return reconstructed_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder_path = \"/content/drive/MyDrive/MUST/KU ppt/DataA2\"\n",
    "example_folder_path = \"/content/drive/MyDrive/MUST/KU ppt/DataA\"\n",
    "\n",
    "training_images = load_and_preprocess_images(training_folder_path, num_images=None, random_seed=random_seed)\n",
    "\n",
    "n_components = 5\n",
    "pca_result_train, pca_reconstructed_train_images, pca_components_train = apply_pca(training_images, n_components)\n",
    "\n",
    "example_images = load_and_preprocess_images(example_folder_path, num_images=None, random_seed=random_seed)\n",
    "\n",
    "num_images_to_display = 10\n",
    "\n",
    "\n",
    "autoencoder = train_autoencoder(training_images, encoding_dim=10, epochs=50, batch_size=32)\n",
    "autoencoder_reconstructed_images = apply_autoencoder(autoencoder, training_images)\n",
    "\n",
    "display_images(example_images, autoencoder_reconstructed_images, num_images=num_images_to_display)\n",
    "\n",
    "\n",
    "vae = train_vae(training_images, encoding_dim=10, epochs=50, batch_size=32)\n",
    "vae_reconstructed_images = apply_vae(vae, training_images)\n",
    "\n",
    "\n",
    "display_images(example_images, vae_reconstructed_images, num_images=num_images_to_display)\n",
    "display_images2(example_images, autoencoder_reconstructed_images, vae_reconstructed_images, num_images=num_images_to_display)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "must",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
